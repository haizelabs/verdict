{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6e0aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install verdict\n",
    "!uv pip install verdict --system\n",
    "\n",
    "# This notebook has been run ahead of time, so you can inspect outputs without making\n",
    "# any API calls. You can set your API key if you want to run the examples yourself.\n",
    "# %env OPENAI_API_KEY=*************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adb5a51-61bc-48aa-b53b-d2856ba62bfc",
   "metadata": {},
   "source": [
    "# Judge\n",
    "\n",
    "Refer to [Eugene Yan's excellent blog post](https://eugeneyan.com/writing/llm-evaluators/#key-considerations-before-adopting-an-llm-evaluator) for a background on LLMs-as-a-Judge. We implement a configurable versions of\n",
    "* Direct Sore Judge (outputs a score for a single sample)\n",
    "  * can also easily be used for reference-based evaluation, as the prompt is completely customizable\n",
    "* Pairwise Judge (choses the better of two samples)\n",
    "  * we extend this to the Best-of-k case with our `BestOfKJudgeUnit`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cde3666-4517-4ce1-b663-09b970955293",
   "metadata": {},
   "source": [
    "## `JudgeUnit` (Direct Score Judge) Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdebbc80-d16a-4949-a3a6-af944e0f335b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pipeline_root.block.unit[DirectScoreJudge]_score': 3}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from verdict import Pipeline\n",
    "from verdict.schema import Schema\n",
    "from verdict.common.judge import JudgeUnit\n",
    "\n",
    "# default scale is DiscreteScale((1, 5))\n",
    "pipeline = Pipeline() \\\n",
    "    >> JudgeUnit().prompt(\"\"\"\n",
    "        Score this on how funny it is.\n",
    "\n",
    "        {source.joke}\n",
    "    \"\"\")\n",
    "\n",
    "response, leaf_node_prefixes = pipeline.run(Schema.of(joke=\"Why did the chicken cross the road? To get to the other side.\"))\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942293d-4ebd-4648-a930-21ca14d982f8",
   "metadata": {},
   "source": [
    "### Configuring\n",
    "\n",
    "#### Scale\n",
    "You can pass an arbitrary `Scale` object using the `scale` argument. For example `BooleanScale` or `ContinuousScale(0, 1)`.\n",
    "\n",
    "\n",
    "#### Explanation\n",
    "Set `explanation=True` to prepend a required `explanation: str` field **before** the `score` field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b9ed7bc-0a6e-413a-9755-6ed3c76fa73a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pipeline_root.block.unit[DirectScoreJudge]_explanation': 'The joke is a classic and simple one that plays on the expectation of a punchline. It is light-hearted and does not contain any inappropriate content or themes. Therefore, it is appropriate for young children.',\n",
       " 'Pipeline_root.block.unit[DirectScoreJudge]_score': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from verdict.scale import BooleanScale\n",
    "\n",
    "response, _ = (Pipeline() \\\n",
    "    >> JudgeUnit(BooleanScale(), explanation=True).prompt(\"\"\"\n",
    "        Is this joke appropriate for young children?\n",
    "\n",
    "        {source.joke}\n",
    "    \"\"\")\n",
    ").run(Schema.of(\n",
    "    joke=\"Why did the chicken cross the road? To get to the other side.\"\n",
    "))\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b1070e-dcc5-4126-af4f-50e5365082fc",
   "metadata": {},
   "source": [
    "## `PairwiseJudgeUnit` (Pairwise Judge) Usage\n",
    "\n",
    "We return the scale index of the chosen  (i.e., with the default `DiscreteScale(['A', 'B'])`, this is either `'A'` or `'B'`). Be aware of [positional bias](verdict.haizelabs.com/docs/cookbook/positional-bias/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b01fbc97-512a-4681-9ad0-9c43fe114777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pipeline_root.block.unit[PairwiseJudge]_explanation': 'Joke B is funnier because it adds a humorous twist related to documentation, which is a more modern and relatable topic for many people, especially in tech or office environments.',\n",
       " 'Pipeline_root.block.unit[PairwiseJudge]_choice': 'B'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from verdict.common.judge import PairwiseJudgeUnit\n",
    "\n",
    "response, _ = (\n",
    "    Pipeline() \\\n",
    "    # default scale is DiscreteScale(['A', 'B'])\n",
    "    # we can pass a custom scale using the `response_options` parameter\n",
    "    >> PairwiseJudgeUnit(explanation=True).prompt(\"\"\"\n",
    "        Chose the funnier joke\n",
    "\n",
    "        A: {source.joke_A}\n",
    "        B: {source.joke_B}\n",
    "    \"\"\")\n",
    ").run(Schema.of(\n",
    "    joke_A=\"Why did the chicken cross the road? To get to the other side.\",\n",
    "    joke_B=\"Why did the chicken cross the road? Because the other side had better documentation.\"\n",
    "))\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b8d72e-abc1-4f17-b043-f3e12e6fd2a6",
   "metadata": {},
   "source": [
    "If we pass the input choices within the `options` list parameter in the Input Schema, we can also pass `original=True` to get the original input associated with the selected index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea66503d-2616-4447-b5a8-e0c79a2ef7c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pipeline_root.block.unit[PairwiseJudge]_explanation': 'Joke B is funnier because it incorporates a humorous twist related to documentation, which can be relatable and amusing, especially in a tech or work context.',\n",
       " 'Pipeline_root.block.unit[PairwiseJudge]_chosen': 'Why did the chicken cross the road? Because the other side had better documentation.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from verdict.common.judge import PairwiseJudgeUnit\n",
    "\n",
    "response, _ = (\n",
    "    Pipeline() \\\n",
    "    >> PairwiseJudgeUnit(explanation=True, original=True).prompt(\"\"\"\n",
    "        Chose the funnier joke\n",
    "\n",
    "        A: {input.options[0]}\n",
    "        B: {input.options[1]}\n",
    "    \"\"\")\n",
    ").run(Schema.of(\n",
    "    options=[\n",
    "        \"Why did the chicken cross the road? To get to the other side.\",\n",
    "        \"Why did the chicken cross the road? Because the other side had better documentation.\"\n",
    "    ]\n",
    "))\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc18b1a-bf3e-4084-9cb4-8dd784007f42",
   "metadata": {},
   "source": [
    "## `BestOfKJudgeUnit` (Multi-Option Judge) Usage\n",
    "\n",
    "Pass an arbitrary `k` options. `PairwiseJudge`is a special case of this implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4d8963e-2ebd-40ee-ae57-e3e8321ebcd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pipeline_root.block.unit[BestOfKJudge]_explanation': 'Joke B is the funniest because it adds a twist related to documentation, which is a humorous take on the classic joke.',\n",
       " 'Pipeline_root.block.unit[BestOfKJudge]_chosen': 'Why did the chicken cross the road? Because the other side had better documentation.'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from verdict.common.judge import BestOfKJudgeUnit\n",
    "\n",
    "response, _ = (\n",
    "    Pipeline() \\\n",
    "    # default scale is [A, ..., kth letter]\n",
    "    >> BestOfKJudgeUnit(k=3, explanation=True, original=True).prompt(\"\"\"\n",
    "        Choose the funniest joke. Respond with the letter index below of the joke that is funniest.\n",
    "\n",
    "        A: {input.options[0]}\n",
    "        B: {input.options[1]}\n",
    "        C: {input.options[2]}\n",
    "    \"\"\")\n",
    ").run(Schema.of(\n",
    "    options=[\n",
    "        \"Why did the chicken cross the road? To get to the other side.\",\n",
    "        \"Why did the chicken cross the road? Because the other side had better documentation.\",\n",
    "        \"Why did the chicken cross the road? I don't know, ask the chicken.\"\n",
    "    ]\n",
    "))\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb457b07-e394-43df-9698-e67185211a85",
   "metadata": {},
   "source": [
    "Dropping the `explanation` allows us to use a Token Probability Extractor, and sample the choice with highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ac092483-b80d-4155-8c25-0f5e75578eb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Pipeline_root.block.unit[BestOfKJudge]_chosen': 'Why did the chicken cross the road? Because the other side had better documentation.'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from verdict.extractor import ArgmaxScoreExtractor\n",
    "\n",
    "response, _ = (\n",
    "    Pipeline() \\\n",
    "    >> BestOfKJudgeUnit(k=3, original=True).prompt(\"\"\"\n",
    "        Choose the funniest joke. Respond with the index below of the joke that is funniest.\n",
    "\n",
    "        1: {input.options[0]}\n",
    "        2: {input.options[1]}\n",
    "        3: {input.options[2]}\n",
    "    \"\"\").extract(ArgmaxScoreExtractor())\n",
    ").run(Schema.of(\n",
    "    options=[\n",
    "        \"Why did the chicken cross the road? To get to the other side.\",\n",
    "        \"Why did the chicken cross the road? Because the other side had better documentation.\",\n",
    "        \"Why did the chicken cross the road? I don't know, ask the chicken.\"\n",
    "    ]\n",
    "))\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "126df928-6914-4b5c-8fdd-cfc2781201c0",
   "metadata": {},
   "source": [
    "# Uncertainty Quantification with Extractors\n",
    "\n",
    "Refer to the [Extractor documentation]() for more context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0160ce95-d052-477e-ad82-f28def1a5ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A': 4.296800258297125e-07, 'B': 0.8519524434689586, 'C': 0.14804712685101548}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from verdict.extractor import TokenProbabilityExtractor\n",
    "\n",
    "response, _ = (\n",
    "    Pipeline() \\\n",
    "    >> BestOfKJudgeUnit(k=3).prompt(\"\"\"\n",
    "        Choose the funniest joke. Respond with the index below of the joke that is funniest.\n",
    "\n",
    "        1: {input.options[0]}\n",
    "        2: {input.options[1]}\n",
    "        3: {input.options[2]}\n",
    "    \"\"\").extract(TokenProbabilityExtractor())\n",
    ").run(Schema.of(\n",
    "    options=[\n",
    "        \"Why did the chicken cross the road? To get to the other side.\",\n",
    "        \"Why did the chicken cross the road? Because the other side had better documentation.\",\n",
    "        \"Why did the chicken cross the road? I don't know, ask the chicken.\",\n",
    "    ]\n",
    "))\n",
    "\n",
    "response['Pipeline_root.block.unit[BestOfKJudge]_distribution']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d01326-3139-4fd9-aaa7-81d85cca5369",
   "metadata": {},
   "source": [
    "So `gpt-4o-mini` finds the second joke to be ~4x funnier than the third joke."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
